{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R420XfnfmOz9"
      },
      "outputs": [],
      "source": [
        "!pip install torch>=1.9.0 torchvision>=0.10.0 numpy>=1.20.0 matplotlib>=3.3.0 seaborn>=0.11.0 opencv-python>=4.5.0 pillow>=8.0.0 scikit-learn>=1.0.0 tqdm>=4.60.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random, string, time\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ],
      "metadata": {
        "id": "aaQOVfzlt7aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random, string, time\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class MnistSequenceDataset(Dataset):\n",
        "    def __init__(self, root, train=True, seq_min=2, seq_max=6, samples=10000, img_h=32):\n",
        "        self.seq_min, self.seq_max = seq_min, seq_max\n",
        "        self.img_h = img_h\n",
        "        base = datasets.MNIST(root, train=train, download=True, transform=transforms.ToTensor())\n",
        "        # bucket MNIST digits for quick sampling\n",
        "        self.by_digit = {d: [] for d in range(10)}\n",
        "        for x,y in base:\n",
        "            self.by_digit[int(y)].append(x)  # x: [1,28,28]\n",
        "        self.samples = samples\n",
        "\n",
        "    def _rand_digit_img(self, d):\n",
        "        x = random.choice(self.by_digit[d])  # [1,28,28]\n",
        "        # augment: random affine + resize to fixed height, keep aspect\n",
        "        aug = transforms.Compose([\n",
        "            transforms.RandomAffine(degrees=8, translate=(0.1,0.1), scale=(0.9,1.1), shear=5),\n",
        "        ])\n",
        "        x = aug(x)\n",
        "        # resize to fixed height, keep width (scale factor)\n",
        "        _, h, w = x.shape\n",
        "        scale = self.img_h / h\n",
        "        new_w = int(round(w * scale))\n",
        "        x = F.interpolate(x.unsqueeze(0), size=(self.img_h, new_w), mode='bilinear', align_corners=False).squeeze(0)\n",
        "        return x\n",
        "\n",
        "    def __len__(self): return self.samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        L = random.randint(self.seq_min, self.seq_max)\n",
        "        digits = [random.randint(0,9) for _ in range(L)]\n",
        "        imgs = [self._rand_digit_img(d) for d in digits]\n",
        "        # small random spacing between digits\n",
        "        spaces = []\n",
        "        for _ in range(L-1):\n",
        "            pad_w = random.randint(1, 6)\n",
        "            spaces.append(torch.zeros(1, self.img_h, pad_w))\n",
        "        # concat along width\n",
        "        pieces = []\n",
        "        for i, im in enumerate(imgs):\n",
        "            pieces.append(im)\n",
        "            if i < L-1: pieces.append(spaces[i])\n",
        "        img = torch.cat(pieces, dim=2)\n",
        "        return img, torch.tensor(digits, dtype=torch.long)"
      ],
      "metadata": {
        "id": "n4AR4CPOZCpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    imgs, labels = zip(*batch)\n",
        "    # pad images by width to max_W\n",
        "    H = imgs[0].shape[1]\n",
        "    W_max = max(im.shape[2] for im in imgs)\n",
        "    padded = []\n",
        "    widths = []\n",
        "    for im in imgs:\n",
        "        pad_w = W_max - im.shape[2]\n",
        "        if pad_w > 0:\n",
        "            im = F.pad(im, (0, pad_w, 0, 0))  # pad width (left,right,top,bottom): (wL,wR,hT,hB)\n",
        "        padded.append(im)\n",
        "        widths.append(W_max)\n",
        "    images = torch.stack(padded, dim=0)  # [B,1,H,W_max]\n",
        "    # labels -> flat targets + lengths (for CTC)\n",
        "    targets = torch.cat([torch.tensor(l, dtype=torch.long) for l in labels])\n",
        "    target_lengths = torch.tensor([len(l) for l in labels], dtype=torch.long)\n",
        "    return images, targets, target_lengths"
      ],
      "metadata": {
        "id": "It34xVLbZl7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CRNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, img_h=32, cnn_out=256, rnn_hidden=256, rnn_layers=2):\n",
        "        super().__init__()\n",
        "        # CNN backbone (kept tiny for speed)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d((2,2)),     # H/2\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d((2,2)),   # H/4\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d((2,1)),  # H/8, keep width\n",
        "            nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Conv2d(512, cnn_out, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d((img_h//8,1))  # collapse height to 1 exactly\n",
        "        )\n",
        "        self.bi = nn.LSTM(input_size=cnn_out, hidden_size=rnn_hidden, num_layers=rnn_layers, bidirectional=True)\n",
        "        self.fc = nn.Linear(rnn_hidden*2, num_classes+1)  # +1 for CTC blank\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,1,H,W]\n",
        "        feats = self.cnn(x)              # [B,C,1,W']\n",
        "        feats = feats.squeeze(2)         # [B,C,W']\n",
        "        feats = feats.permute(2,0,1)     # [T=W', B, C]\n",
        "        seq, _ = self.bi(feats)          # [T, B, 2H]\n",
        "        logits = self.fc(seq)            # [T, B, classes+blank]\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs\n"
      ],
      "metadata": {
        "id": "nggz3w19Zz-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_train(num_epochs=5, batch_size=64, samples_train=20000, samples_val=2000, lr=1e-3, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    train_ds = MnistSequenceDataset('./data', train=True, samples=samples_train)\n",
        "    val_ds   = MnistSequenceDataset('./data', train=False, samples=samples_val)\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_batch, pin_memory=True)\n",
        "    val_dl   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=collate_batch, pin_memory=True)\n",
        "\n",
        "    model = CRNN().to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    ctc_loss = nn.CTCLoss(blank=10, zero_infinity=True)  # classes 0..9, blank=10\n",
        "\n",
        "    def step(dl, train=True):\n",
        "        model.train(train)\n",
        "        total, n = 0.0, 0\n",
        "        for images, targets, target_lengths in dl:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            # forward\n",
        "            logp = model(images)                # [T,B,C]\n",
        "            T, B, C = logp.shape\n",
        "            input_lengths = torch.full((B,), T, dtype=torch.long, device=device)\n",
        "            loss = ctc_loss(logp, targets, input_lengths, target_lengths)\n",
        "            if train:\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
        "                opt.step()\n",
        "            total += loss.item() * B\n",
        "            n += B\n",
        "        return total / max(n,1)\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        tr = step(train_dl, True)\n",
        "        va = step(val_dl, False)\n",
        "        print(f\"Epoch {epoch:02d} | train CTC loss: {tr:.3f} | val CTC loss: {va:.3f}\")\n",
        "\n",
        "    return model, val_dl\n"
      ],
      "metadata": {
        "id": "DCEHvPGVZ27L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(log_probs):  # log_probs: [T,B,C]\n",
        "    # choose argmax at each time, collapse repeats, remove blanks\n",
        "    blank = 10\n",
        "    T,B,C = log_probs.shape\n",
        "    pred = log_probs.argmax(dim=-1).transpose(0,1)  # [B,T]\n",
        "    sequences = []\n",
        "    for b in range(B):\n",
        "        prev = blank\n",
        "        out = []\n",
        "        for t in range(T):\n",
        "            p = int(pred[b,t])\n",
        "            if p != blank and p != prev:\n",
        "                out.append(p)\n",
        "            prev = p\n",
        "        sequences.append(out)\n",
        "    return sequences  # list of lists of ints\n"
      ],
      "metadata": {
        "id": "apDVkCWgZ5k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, val_dl = ctc_train(num_epochs=5, samples_train=15000, samples_val=1000)\n",
        "\n",
        "# quick sanity check on a few batches\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, targets, target_lengths in val_dl:\n",
        "        logp = model(images.to(next(model.parameters()).device))\n",
        "        hyps = greedy_decode(logp.cpu())\n",
        "        # detokenize first 5 predictions & targets\n",
        "        i = 0\n",
        "        off = 0\n",
        "        for _ in range(5):\n",
        "            L = int(target_lengths[i])\n",
        "            gt = targets[off:off+L].tolist()\n",
        "            pr = hyps[i]\n",
        "            print(f\"GT: {''.join(map(str,gt))} | PR: {''.join(map(str,pr))}\")\n",
        "            off += L\n",
        "            i += 1\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imEHUU0nZ7Nh",
        "outputId": "e247ac6b-870e-4ae9-822a-5776f971ddae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train CTC loss: 2.102 | val CTC loss: 0.265\n",
            "Epoch 02 | train CTC loss: 0.169 | val CTC loss: 0.139\n",
            "Epoch 03 | train CTC loss: 0.087 | val CTC loss: 0.068\n",
            "Epoch 04 | train CTC loss: 0.064 | val CTC loss: 0.069\n",
            "Epoch 05 | train CTC loss: 0.058 | val CTC loss: 0.061\n",
            "GT: 6434 | PR: 6434\n",
            "GT: 39225 | PR: 39225\n",
            "GT: 180 | PR: 180\n",
            "GT: 999 | PR: 999\n",
            "GT: 69 | PR: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make a dataset\n",
        "ds = MnistSequenceDataset('./data', train=True, samples=10)\n",
        "\n",
        "# pick one sample\n",
        "img, label = ds[0]   # img: [1,H,W], label: tensor of digits\n",
        "\n",
        "print(\"Digits:\", label.tolist())\n",
        "\n",
        "# convert [1,H,W] -> [H,W]\n",
        "plt.imshow(img.squeeze(0).numpy(), cmap='gray')\n",
        "plt.title(\"Digits: \" + ''.join(map(str, label.tolist())))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P5APjGt4a4S8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}